{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6961ad",
   "metadata": {},
   "source": [
    "# ðŸ”§ Hyperparameter Tuning in Machine Learning\n",
    "\n",
    "## ðŸ“˜ Definition\n",
    "\n",
    "**Hyperparameter tuning** is the process of finding the best set of hyperparameters for a machine learning model to improve its accuracy and performance on unseen data. Hyperparameters are like configuration settingsâ€”such as learning rate, number of trees, or depth of a modelâ€”that are set **before** training begins.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© Types of Hyperparameter Tuning (with Examples, Pros, and Cons)\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Grid Search**\n",
    "\n",
    "**Description:**  \n",
    "Tries every possible combination of hyperparameter values from a predefined grid.\n",
    "\n",
    "**Example:**  \n",
    "Imagine tuning a decision tree. You try every combination of:\n",
    "- max_depth: [3, 5, 7]\n",
    "- min_samples_split: [2, 4]\n",
    "\n",
    "This gives you 3 Ã— 2 = 6 models to train and compare.\n",
    "\n",
    "**Pros:**\n",
    "- Simple and systematic\n",
    "- Guarantees testing all combinations\n",
    "\n",
    "**Cons:**\n",
    "- Very slow with many parameters\n",
    "- Tries even the bad combinations\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Random Search**\n",
    "\n",
    "**Description:**  \n",
    "Randomly selects combinations of hyperparameters from given ranges.\n",
    "\n",
    "**Example:**  \n",
    "You randomly choose:\n",
    "- max_depth: any value between 1 and 10\n",
    "- learning_rate: any value between 0.01 and 0.3  \n",
    "Instead of testing every pair, you randomly test, say, 10 combinations.\n",
    "\n",
    "**Pros:**\n",
    "- Faster than grid search\n",
    "- Better chance to find good parameters in less time\n",
    "\n",
    "**Cons:**\n",
    "- May miss the best combination\n",
    "- Still needs you to define a good range\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Bayesian Optimization**\n",
    "\n",
    "**Description:**  \n",
    "Uses past trial results to decide the next best combination to try (smart search).\n",
    "\n",
    "**Example:**  \n",
    "You try a few combinations first. Based on which ones worked well, it picks the next likely best combination instead of guessing randomly.\n",
    "\n",
    "**Pros:**\n",
    "- Learns from past tries\n",
    "- Fewer model runs needed\n",
    "\n",
    "**Cons:**\n",
    "- Harder to implement\n",
    "- Can get stuck in local optima\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Gradient-based Optimization**\n",
    "\n",
    "**Description:**  \n",
    "Uses gradients (slopes) to adjust hyperparameters in the direction of improvement.\n",
    "\n",
    "**Example:**  \n",
    "In deep learning, you start with a learning rate of 0.1. Based on performance feedback, the optimizer gradually reduces it to improve accuracy.\n",
    "\n",
    "**Pros:**\n",
    "- Fast convergence\n",
    "- Useful in neural networks\n",
    "\n",
    "**Cons:**\n",
    "- Only works when gradients are available\n",
    "- Not applicable to all algorithms\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Evolutionary Algorithms**\n",
    "\n",
    "**Description:**  \n",
    "Inspired by natural evolutionâ€”keeps good combinations, mutates them, and tries new ones.\n",
    "\n",
    "**Example:**  \n",
    "Imagine a population of 10 models with different hyperparameters. The best ones \"mate\" and produce new combinations with random changes (\"mutations\").\n",
    "\n",
    "**Pros:**\n",
    "- Good at exploring complex spaces\n",
    "- Avoids local optima\n",
    "\n",
    "**Cons:**\n",
    "- Requires many model runs\n",
    "- Complex to configure\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Automated Machine Learning (AutoML)**\n",
    "\n",
    "**Description:**  \n",
    "Fully automates the process of model and hyperparameter selection.\n",
    "\n",
    "**Example:**  \n",
    "You just give the data and target to an AutoML tool. It tries various models and hyperparameters behind the scenes and gives you the best one.\n",
    "\n",
    "**Pros:**\n",
    "- Saves time and effort\n",
    "- Good performance with minimal tuning\n",
    "\n",
    "**Cons:**\n",
    "- Limited control and transparency\n",
    "- Can be resource-intensive\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Summary Table\n",
    "\n",
    "| Method              | Pros                                  | Cons                                  | Example Idea                             |\n",
    "|---------------------|----------------------------------------|----------------------------------------|-------------------------------------------|\n",
    "| Grid Search         | Tests all options                      | Slow for many parameters              | Trying all learning rates and depths      |\n",
    "| Random Search       | Fast, simple                           | May miss best combo                   | Randomly trying values in a range         |\n",
    "| Bayesian Optimization | Smart, learns from results          | Harder to set up                      | Tries best next guess based on past runs  |\n",
    "| Gradient-based      | Quick adjustment                      | Limited use                           | Adjust learning rate over time            |\n",
    "| Evolutionary        | Good for complex tuning               | Slow, needs setup                     | Like genetic evolution of models          |\n",
    "| AutoML              | Fully automated                       | Opaque, heavy                         | Tool picks model + tuning for you         |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§® Common Hyperparameters (Examples)\n",
    "\n",
    "| Algorithm        | Hyperparameters                               |\n",
    "|------------------|-----------------------------------------------|\n",
    "| Linear Regression | Regularization (L1, L2), alpha               |\n",
    "| SVM              | Kernel type, C, gamma                         |\n",
    "| Random Forest     | n_estimators, max_depth, min_samples_split   |\n",
    "| Neural Networks   | Learning rate, batch size, epochs, layers    |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¢ Formula-like Representation\n",
    "\n",
    "There is no single formula for hyperparameter tuning, but it is often expressed as an optimization problem:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_{\\theta \\in \\Theta} \\mathcal{L}_{val}(f_{\\theta}(X_{train}), y_{val})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\theta $: set of hyperparameters  \n",
    "- $ \\Theta $: hyperparameter search space  \n",
    "- $ \\mathcal{L}_{val} $: validation loss  \n",
    "- $ f_{\\theta} $: model trained with hyperparameters $ \\theta $  \n",
    "- $ X_{train}, y_{val} $: training and validation datasets  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Best Practices\n",
    "\n",
    "- Use **cross-validation** to avoid overfitting while tuning.\n",
    "- **Start with random search**, then refine with **Bayesian or grid**.\n",
    "- Avoid using too many combinationsâ€”focus on **important hyperparameters**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593f8ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
