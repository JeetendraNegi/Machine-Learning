{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Techniques in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition:\n",
    "Regularization is a technique used to prevent overfitting by adding a penalty to the model's complexity.\n",
    "It helps improve the generalization of the model, ensuring that it performs well not just on the training data but also on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Regularization:\n",
    "\n",
    "#### 1. **L2 Regularization (Ridge Regression):**\n",
    "- **Formula:**\n",
    "$$\n",
    "\\text{Loss function} = \\text{Original Loss} + \\lambda \\sum_{i=1}^{n} w_i^2\n",
    "$$\n",
    "- Tends to shrink coefficients but doesn't set them to zero.\n",
    "\n",
    "#### 2. **L1 Regularization (Lasso Regression):**\n",
    "- **Formula:**\n",
    "$$\n",
    "\\text{Loss function} = \\text{Original Loss} + \\lambda \\sum_{i=1}^{n} |w_i|\n",
    "$$\n",
    "- Tends to drive some coefficients exactly to zero, leading to sparse models.\n",
    "\n",
    "#### 3. **Elastic Net Regularization:**\n",
    "- **Formula:**\n",
    "$$\n",
    "\\text{Loss function} = \\text{Original Loss} + \\lambda \\left( \\alpha \\sum_{i=1}^{n} |w_i| + (1-\\alpha) \\sum_{i=1}^{n} w_i^2 \\right)\n",
    "$$\n",
    "- A mix of L1 and L2 regularization for a balance between feature selection and shrinkage.\n",
    "\n",
    "#### 4. **Early Stopping (for Neural Networks):**\n",
    "- **Description:**\n",
    "  - Regularization technique for iterative models like neural networks. \n",
    "  - Training stops early if validation performance starts degrading, preventing overfitting.\n",
    "  - Where $ \\ w_i$ is slop of the curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table\n",
    "\n",
    "| **Regularization Type** | **Penalty** | **Main Effect** |\n",
    "|-------------------------|-------------|------------------|\n",
    "| **L2 (Ridge)** | $ \\lambda \\sum_{i=1}^{n} w_i^2 $ | Shrinks coefficients but doesn't set them to zero |\n",
    "| **L1 (Lasso)** | $ \\lambda \\sum_{i=1}^{n} \\lvert w_i \\rvert $ | Shrinks some coefficients to zero (feature selection) |\n",
    "| **Elastic Net** | $ \\lambda \\left( \\alpha \\sum_{i=1}^{n} \\lvert w_i \\rvert + (1-\\alpha) \\sum_{i=1}^{n} w_i^2 \\right) $ | Mix of L1 and L2 (balance between feature selection and shrinkage) |\n",
    "| **Early Stopping** | Stops training if validation performance degrades | Prevents overfitting in iterative models like neural networks |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
